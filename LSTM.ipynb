{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Needed for one hot encoding\n",
    "def convert_to_categories(n):\n",
    "    if n == 0 :\n",
    "        return 0\n",
    "    if n == 5:\n",
    "        return 1\n",
    "    if n == 10:\n",
    "        return 2\n",
    "    \n",
    "def convert_to_binary(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "TRAINING_DATA_PATH='/home/mlsg/DiskA/others/ratios'\n",
    "VALIDATION_DATA_PATH='/home/mlsg/DiskB/others/ratios'\n",
    "SEQUENCE_LENGTH = 240\n",
    "TIME_LENGTH = 5\n",
    "conversion = convert_to_binary\n",
    "\n",
    "# CSV files format\n",
    "# [frame, eye aspect ratio, eye_circularity, mouth aspect ratio, mar/ear, 4 more(normalized versions of left 4 in order)]\n",
    "\n",
    "# Should return an array\n",
    "def get_row(row):\n",
    "    return row[5:9] \n",
    "\n",
    "label_0 = []\n",
    "label_5 = []\n",
    "label_10 = []\n",
    "\n",
    "# For now we only care about eye aspect ratio\n",
    "for csv_dir in os.listdir(TRAINING_DATA_PATH):\n",
    "# # TODO: Change to load more data\n",
    "# for csv_dir in ['12']:\n",
    "    full_path = TRAINING_DATA_PATH + '/' + csv_dir\n",
    "    endings = ['0', '5', '10']\n",
    "    \n",
    "    for ending in endings:\n",
    "        rows = []\n",
    "        with open(full_path + '/' + ending + '.csv') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if len(row) <= 5:\n",
    "                    break\n",
    "                rows.append(row)\n",
    "#         Sort by frame number\n",
    "        rows.sort(key=lambda x:int(x[0]))\n",
    "        rows = [get_row(row) for row in rows]\n",
    "        \n",
    "        # Too few faces, bad video\n",
    "        if len(rows) < SEQUENCE_LENGTH:\n",
    "            continue\n",
    "        # Get the last few rows\n",
    "        freqs = rows[-SEQUENCE_LENGTH:]\n",
    "        \n",
    "        if ending == '0':\n",
    "            label_0 += (freqs)\n",
    "        elif ending == '5':\n",
    "            kkk = 2\n",
    "#             label_5 += (freqs)\n",
    "        else:\n",
    "            label_10 += (freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the validation data\n",
    "validation_label_0 = []\n",
    "validation_label_5 = []\n",
    "validation_label_10 = []\n",
    "# For now we only care about eye aspect ratio\n",
    "for csv_dir in os.listdir(VALIDATION_DATA_PATH):\n",
    "# # TODO: Change to load more data\n",
    "# for csv_dir in ['12']:\n",
    "    full_path = VALIDATION_DATA_PATH + '/' + csv_dir\n",
    "    endings = ['0', '5', '10']\n",
    "    \n",
    "    for ending in endings:\n",
    "        rows = []\n",
    "        with open(full_path + '/' + ending + '.csv') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                if len(row) <= 5:\n",
    "                    break\n",
    "                rows.append(row)\n",
    "        # Sort by frame number\n",
    "        rows.sort(key=lambda x:int(x[0]))\n",
    "        rows = [get_row(row) for row in rows]\n",
    "        \n",
    "        # Too few faces, bad video\n",
    "        if len(rows) < SEQUENCE_LENGTH:\n",
    "            continue\n",
    "        # Get the last few rows from video\n",
    "        freqs = rows[-SEQUENCE_LENGTH:]\n",
    "\n",
    "        if ending == '0':\n",
    "            validation_label_0 += (freqs)\n",
    "        elif ending== '5':\n",
    "            kkk = 2\n",
    "            # do nothing\n",
    "#             validation_label_5 += (freqs)\n",
    "        else:\n",
    "            validation_label_10 += (freqs)\n",
    "\n",
    "x_validation_data = validation_label_0 + validation_label_5 + validation_label_10\n",
    "y_validation_data = [0] * len(validation_label_0) + [5] * len(validation_label_5) + [10] * len(validation_label_10)\n",
    "\n",
    "new_valid_data_y = []\n",
    "# Label vaidation data\n",
    "for i in range(0, len(y_validation_data), TIME_LENGTH):\n",
    "    new_valid_data_y.append(conversion(y_validation_data[i]))\n",
    "y_validation_data = np.array(new_valid_data_y)\n",
    "\n",
    "len(x_validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15600, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x = label_0 + label_5 + label_10\n",
    "data_x = np.array(data_x)\n",
    "\n",
    "# Get them labels\n",
    "data_y = [0] * len(label_0) + [5] * len(label_5) + [10] * len(label_10)\n",
    "# Label training data\n",
    "new_data_y = []\n",
    "for i in range(0, len(data_y), TIME_LENGTH):\n",
    "    new_data_y.append(conversion(data_y[i]))\n",
    "data_y = np.array(new_data_y)\n",
    "\n",
    "# data_x = np.array(data_x)\n",
    "input_length = len(data_y)\n",
    "data_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data_x = data_x.reshape(len(data_x) // TIME_LENGTH, TIME_LENGTH, 4)\n",
    "x_validation_data = np.array(x_validation_data).reshape(len(x_validation_data) // TIME_LENGTH, TIME_LENGTH, 4)\n",
    "\n",
    "# c = list(zip(data_x, data_y))\n",
    "# random.shuffle(c)\n",
    "# data_x, data_y = zip(*c)\n",
    "\n",
    "# d = list(zip(x_validation_data, y_validation_data))\n",
    "# random.shuffle(d)\n",
    "# x_validation_data, y_validation_data = zip(*d)\n",
    "\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "x_validation_data = np.array(x_validation_data)\n",
    "y_validation_data = np.array(y_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3120 samples, validate on 1920 samples\n",
      "Epoch 1/30\n",
      "3120/3120 [==============================] - 5s 2ms/step - loss: 4.3700 - accuracy: 0.2949 - val_loss: 0.7478 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "3120/3120 [==============================] - 3s 889us/step - loss: 0.9784 - accuracy: 0.5212 - val_loss: 0.8001 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "3120/3120 [==============================] - 3s 896us/step - loss: 0.7994 - accuracy: 0.5756 - val_loss: 0.6337 - val_accuracy: 0.6411\n",
      "Epoch 4/30\n",
      "3120/3120 [==============================] - 3s 873us/step - loss: 0.7238 - accuracy: 0.6244 - val_loss: 0.6115 - val_accuracy: 0.6714\n",
      "Epoch 5/30\n",
      "3120/3120 [==============================] - 3s 877us/step - loss: 0.6820 - accuracy: 0.6356 - val_loss: 0.5839 - val_accuracy: 0.6906\n",
      "Epoch 6/30\n",
      "3120/3120 [==============================] - 3s 899us/step - loss: 0.6606 - accuracy: 0.6446 - val_loss: 0.5950 - val_accuracy: 0.6818\n",
      "Epoch 7/30\n",
      "3120/3120 [==============================] - 3s 877us/step - loss: 0.6440 - accuracy: 0.6436 - val_loss: 0.5890 - val_accuracy: 0.6620\n",
      "Epoch 8/30\n",
      "3120/3120 [==============================] - 3s 882us/step - loss: 0.6271 - accuracy: 0.6510 - val_loss: 0.5737 - val_accuracy: 0.6958\n",
      "Epoch 9/30\n",
      "3120/3120 [==============================] - 3s 887us/step - loss: 0.6268 - accuracy: 0.6545 - val_loss: 0.5757 - val_accuracy: 0.6776\n",
      "Epoch 10/30\n",
      "3120/3120 [==============================] - 3s 875us/step - loss: 0.6077 - accuracy: 0.6651 - val_loss: 0.5709 - val_accuracy: 0.6922\n",
      "Epoch 11/30\n",
      "3120/3120 [==============================] - 3s 882us/step - loss: 0.6086 - accuracy: 0.6641 - val_loss: 0.5665 - val_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "3120/3120 [==============================] - 3s 860us/step - loss: 0.6173 - accuracy: 0.6564 - val_loss: 0.5814 - val_accuracy: 0.6828\n",
      "Epoch 13/30\n",
      "3120/3120 [==============================] - 3s 879us/step - loss: 0.6070 - accuracy: 0.6647 - val_loss: 0.5815 - val_accuracy: 0.6802\n",
      "Epoch 14/30\n",
      "3120/3120 [==============================] - 3s 898us/step - loss: 0.6065 - accuracy: 0.6705 - val_loss: 0.5700 - val_accuracy: 0.7010\n",
      "Epoch 15/30\n",
      "3120/3120 [==============================] - 3s 935us/step - loss: 0.6104 - accuracy: 0.6638 - val_loss: 0.5797 - val_accuracy: 0.6911\n",
      "Epoch 16/30\n",
      "3120/3120 [==============================] - 3s 945us/step - loss: 0.6040 - accuracy: 0.6689 - val_loss: 0.5609 - val_accuracy: 0.7109\n",
      "Epoch 17/30\n",
      "3120/3120 [==============================] - 3s 956us/step - loss: 0.6073 - accuracy: 0.6673 - val_loss: 0.5758 - val_accuracy: 0.7021\n",
      "Epoch 18/30\n",
      "3120/3120 [==============================] - 3s 921us/step - loss: 0.6011 - accuracy: 0.6756 - val_loss: 0.5737 - val_accuracy: 0.6958\n",
      "Epoch 19/30\n",
      "3120/3120 [==============================] - 3s 933us/step - loss: 0.5939 - accuracy: 0.6750 - val_loss: 0.5618 - val_accuracy: 0.7094\n",
      "Epoch 20/30\n",
      "3120/3120 [==============================] - 3s 925us/step - loss: 0.5980 - accuracy: 0.6715 - val_loss: 0.5806 - val_accuracy: 0.6901\n",
      "Epoch 21/30\n",
      "3120/3120 [==============================] - 3s 976us/step - loss: 0.5959 - accuracy: 0.6801 - val_loss: 0.5720 - val_accuracy: 0.6979\n",
      "Epoch 22/30\n",
      "3120/3120 [==============================] - 3s 941us/step - loss: 0.6051 - accuracy: 0.6772 - val_loss: 0.5663 - val_accuracy: 0.7068\n",
      "Epoch 23/30\n",
      "3120/3120 [==============================] - 3s 939us/step - loss: 0.5944 - accuracy: 0.6808 - val_loss: 0.5692 - val_accuracy: 0.7016\n",
      "Epoch 24/30\n",
      "3120/3120 [==============================] - 3s 929us/step - loss: 0.5924 - accuracy: 0.6792 - val_loss: 0.5729 - val_accuracy: 0.6969\n",
      "Epoch 25/30\n",
      "3120/3120 [==============================] - 3s 942us/step - loss: 0.6004 - accuracy: 0.6821 - val_loss: 0.5610 - val_accuracy: 0.7156\n",
      "Epoch 26/30\n",
      "3120/3120 [==============================] - 3s 909us/step - loss: 0.5942 - accuracy: 0.6840 - val_loss: 0.5716 - val_accuracy: 0.6932\n",
      "Epoch 27/30\n",
      "3120/3120 [==============================] - 3s 935us/step - loss: 0.5996 - accuracy: 0.6804 - val_loss: 0.5657 - val_accuracy: 0.7089\n",
      "Epoch 28/30\n",
      "3120/3120 [==============================] - 3s 902us/step - loss: 0.5878 - accuracy: 0.6955 - val_loss: 0.5658 - val_accuracy: 0.7005\n",
      "Epoch 29/30\n",
      "3120/3120 [==============================] - 3s 898us/step - loss: 0.5961 - accuracy: 0.6801 - val_loss: 0.5622 - val_accuracy: 0.7120\n",
      "Epoch 30/30\n",
      "3120/3120 [==============================] - 3s 925us/step - loss: 0.5833 - accuracy: 0.6885 - val_loss: 0.5620 - val_accuracy: 0.7156\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 5, 240)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 5, 4)              3920      \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 12,561\n",
      "Trainable params: 12,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding, Flatten, Bidirectional\n",
    "from keras.optimizers import Adam, RMSprop, Nadam, SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(SEQUENCE_LENGTH, activation='sigmoid'))\n",
    "model.add((LSTM(4, return_sequences=True,\n",
    "                       input_shape=(TIME_LENGTH, 4),\n",
    "                       dropout=0.5)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='sigmoid')) #FC1\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu')) #FC2\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='tanh'))#Output Layer\n",
    "optimizer = Nadam()\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "summary = model.fit(data_x, data_y, epochs=30, validation_data=(x_validation_data, y_validation_data), batch_size=10)\n",
    "# summary = model.fit(data_x, data_y, epochs=2, validation_split=0.5, batch_size=10)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Findings: Optimal seqence length at 15 (not 30), optional dropout >= 0.5, need the relu activation\n",
    "# Circularity of eye is not particularly useful\n",
    "\n",
    "# DO NOT TOUCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3120 samples, validate on 1920 samples\n",
      "Epoch 1/40\n",
      "3120/3120 [==============================] - 2s 722us/step - loss: 1.1162 - accuracy: 0.4769 - val_loss: 0.9666 - val_accuracy: 0.6479\n",
      "Epoch 2/40\n",
      "3120/3120 [==============================] - 1s 379us/step - loss: 0.9809 - accuracy: 0.5378 - val_loss: 0.9078 - val_accuracy: 0.6828\n",
      "Epoch 3/40\n",
      "3120/3120 [==============================] - 1s 387us/step - loss: 0.9208 - accuracy: 0.5462 - val_loss: 0.8658 - val_accuracy: 0.6755\n",
      "Epoch 4/40\n",
      "3120/3120 [==============================] - 1s 386us/step - loss: 0.8782 - accuracy: 0.5356 - val_loss: 0.8306 - val_accuracy: 0.6625\n",
      "Epoch 5/40\n",
      "3120/3120 [==============================] - 1s 389us/step - loss: 0.8427 - accuracy: 0.5426 - val_loss: 0.8039 - val_accuracy: 0.6578\n",
      "Epoch 6/40\n",
      "3120/3120 [==============================] - 1s 376us/step - loss: 0.8188 - accuracy: 0.5391 - val_loss: 0.7844 - val_accuracy: 0.6594\n",
      "Epoch 7/40\n",
      "3120/3120 [==============================] - 1s 374us/step - loss: 0.7949 - accuracy: 0.5561 - val_loss: 0.7684 - val_accuracy: 0.6354\n",
      "Epoch 8/40\n",
      "3120/3120 [==============================] - 1s 373us/step - loss: 0.7796 - accuracy: 0.5433 - val_loss: 0.7575 - val_accuracy: 0.6057\n",
      "Epoch 9/40\n",
      "3120/3120 [==============================] - 1s 380us/step - loss: 0.7669 - accuracy: 0.5391 - val_loss: 0.7428 - val_accuracy: 0.6109\n",
      "Epoch 10/40\n",
      "3120/3120 [==============================] - 1s 380us/step - loss: 0.7530 - accuracy: 0.5506 - val_loss: 0.7354 - val_accuracy: 0.5443\n",
      "Epoch 11/40\n",
      "3120/3120 [==============================] - 1s 386us/step - loss: 0.7485 - accuracy: 0.5397 - val_loss: 0.7306 - val_accuracy: 0.5344\n",
      "Epoch 12/40\n",
      "3120/3120 [==============================] - 1s 374us/step - loss: 0.7335 - accuracy: 0.5545 - val_loss: 0.7170 - val_accuracy: 0.5516\n",
      "Epoch 13/40\n",
      "3120/3120 [==============================] - 1s 379us/step - loss: 0.7305 - accuracy: 0.5462 - val_loss: 0.7115 - val_accuracy: 0.5448\n",
      "Epoch 14/40\n",
      "3120/3120 [==============================] - 1s 385us/step - loss: 0.7180 - accuracy: 0.5593 - val_loss: 0.6930 - val_accuracy: 0.6115\n",
      "Epoch 15/40\n",
      "3120/3120 [==============================] - 1s 371us/step - loss: 0.7195 - accuracy: 0.5516 - val_loss: 0.6918 - val_accuracy: 0.5818\n",
      "Epoch 16/40\n",
      "3120/3120 [==============================] - 1s 397us/step - loss: 0.7090 - accuracy: 0.5647 - val_loss: 0.6871 - val_accuracy: 0.5911\n",
      "Epoch 17/40\n",
      "3120/3120 [==============================] - 1s 375us/step - loss: 0.7083 - accuracy: 0.5596 - val_loss: 0.6729 - val_accuracy: 0.6708\n",
      "Epoch 18/40\n",
      "3120/3120 [==============================] - 1s 388us/step - loss: 0.6951 - accuracy: 0.5766 - val_loss: 0.6642 - val_accuracy: 0.6792\n",
      "Epoch 19/40\n",
      "3120/3120 [==============================] - 1s 388us/step - loss: 0.6947 - accuracy: 0.5696 - val_loss: 0.6624 - val_accuracy: 0.6729\n",
      "Epoch 20/40\n",
      "3120/3120 [==============================] - 1s 377us/step - loss: 0.6916 - accuracy: 0.5821 - val_loss: 0.6665 - val_accuracy: 0.6568\n",
      "Epoch 21/40\n",
      "3120/3120 [==============================] - 1s 375us/step - loss: 0.6893 - accuracy: 0.5846 - val_loss: 0.6601 - val_accuracy: 0.6599\n",
      "Epoch 22/40\n",
      "3120/3120 [==============================] - 1s 368us/step - loss: 0.6851 - accuracy: 0.5814 - val_loss: 0.6645 - val_accuracy: 0.6380\n",
      "Epoch 23/40\n",
      "3120/3120 [==============================] - 1s 377us/step - loss: 0.6819 - accuracy: 0.5853 - val_loss: 0.6583 - val_accuracy: 0.6422\n",
      "Epoch 24/40\n",
      "3120/3120 [==============================] - 1s 384us/step - loss: 0.6804 - accuracy: 0.5811 - val_loss: 0.6521 - val_accuracy: 0.6500\n",
      "Epoch 25/40\n",
      "3120/3120 [==============================] - 1s 374us/step - loss: 0.6748 - accuracy: 0.5875 - val_loss: 0.6548 - val_accuracy: 0.6375\n",
      "Epoch 26/40\n",
      "3120/3120 [==============================] - 1s 375us/step - loss: 0.6765 - accuracy: 0.5885 - val_loss: 0.6502 - val_accuracy: 0.6406\n",
      "Epoch 27/40\n",
      "3120/3120 [==============================] - 1s 384us/step - loss: 0.6674 - accuracy: 0.5939 - val_loss: 0.6487 - val_accuracy: 0.6401\n",
      "Epoch 28/40\n",
      "3120/3120 [==============================] - 1s 367us/step - loss: 0.6777 - accuracy: 0.5824 - val_loss: 0.6572 - val_accuracy: 0.6344\n",
      "Epoch 29/40\n",
      "3120/3120 [==============================] - 1s 373us/step - loss: 0.6765 - accuracy: 0.5804 - val_loss: 0.6615 - val_accuracy: 0.6187\n",
      "Epoch 30/40\n",
      "3120/3120 [==============================] - 1s 372us/step - loss: 0.6638 - accuracy: 0.5990 - val_loss: 0.6566 - val_accuracy: 0.6245\n",
      "Epoch 31/40\n",
      "3120/3120 [==============================] - 1s 373us/step - loss: 0.6700 - accuracy: 0.5907 - val_loss: 0.6652 - val_accuracy: 0.6031\n",
      "Epoch 32/40\n",
      "3120/3120 [==============================] - 1s 376us/step - loss: 0.6633 - accuracy: 0.5942 - val_loss: 0.6642 - val_accuracy: 0.6026\n",
      "Epoch 33/40\n",
      "3120/3120 [==============================] - 1s 375us/step - loss: 0.6673 - accuracy: 0.5894 - val_loss: 0.6655 - val_accuracy: 0.5958\n",
      "Epoch 34/40\n",
      "3120/3120 [==============================] - 1s 368us/step - loss: 0.6524 - accuracy: 0.6080 - val_loss: 0.6678 - val_accuracy: 0.5849\n",
      "Epoch 35/40\n",
      "3120/3120 [==============================] - 1s 391us/step - loss: 0.6547 - accuracy: 0.6045 - val_loss: 0.6661 - val_accuracy: 0.5901\n",
      "Epoch 36/40\n",
      "3120/3120 [==============================] - 1s 392us/step - loss: 0.6501 - accuracy: 0.6074 - val_loss: 0.6671 - val_accuracy: 0.5880\n",
      "Epoch 37/40\n",
      "3120/3120 [==============================] - 1s 391us/step - loss: 0.6505 - accuracy: 0.6109 - val_loss: 0.6681 - val_accuracy: 0.5839\n",
      "Epoch 38/40\n",
      "3120/3120 [==============================] - 1s 385us/step - loss: 0.6522 - accuracy: 0.6090 - val_loss: 0.6677 - val_accuracy: 0.5776\n",
      "Epoch 39/40\n",
      "3120/3120 [==============================] - 1s 381us/step - loss: 0.6561 - accuracy: 0.6071 - val_loss: 0.6643 - val_accuracy: 0.5859\n",
      "Epoch 40/40\n",
      "3120/3120 [==============================] - 1s 384us/step - loss: 0.6542 - accuracy: 0.6067 - val_loss: 0.6747 - val_accuracy: 0.5641\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 5, 4)              144       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 84        \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DO NOT TOUCH\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding, Flatten, Bidirectional\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# DO NOT TOUCH, # DO NOT TOUCH\n",
    "\n",
    "# Alternative optimize\n",
    "sgd = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Use to_categorical to convert to one hot encoding\n",
    "encoded_data_y = to_categorical(data_y)\n",
    "encoded_y_validation_data = to_categorical(y_validation_data)\n",
    "\n",
    "# model.add(Dense(SEQUENCE_LENGTH, activation='sigmoid'))\n",
    "model.add((LSTM(4, return_sequences=True,\n",
    "                       input_shape=(TIME_LENGTH, 4,),\n",
    "                       dropout=0.7)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Dense is fully connected layer. 16 hidden units\n",
    "# activation for lstm is basically sigmoid or tanh\n",
    "model.add(Dense(4, activation='relu')) #FC1\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(3, activation='softmax'))#Output Layer\n",
    "optimizer = 'adam'\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "summary = model.fit(data_x, encoded_data_y, epochs=40, validation_data=(x_validation_data, encoded_y_validation_data), batch_size=20)\n",
    "# summary = model.fit(data_x, data_y, epochs=2, validation_split=0.5, batch_size=10)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Joshua notes\n",
    "\"\"\"\n",
    "Switching to categorical cross entropy drastically increased performance\n",
    "My guess is that this is because we have 3 categories in the first place, so we had to use some form of hot encoding \n",
    "to get the correct answer\n",
    "\n",
    "My first try was only using mouth aspect ratio and mar/ear, both for the normalized and unnormaized values\n",
    "\n",
    "My second try switched to all the normalized ratios, and it improved things even more\n",
    "\n",
    "Ths above was done with dropout 0.6 and LSTM number 8, with adam optimizer\n",
    "\n",
    "Increasing number of neurons also drastically overfits which is a problem\n",
    "\n",
    "Best so far, 8, 4, 4, 3 around 50% accuracy\n",
    "\n",
    "Notes and TODO: try varying the 5 to 15 and more for the sequences, maybe feed in more frames also.\n",
    "\n",
    "dropout 0.7, 4,3,3 with 240, 5 achieved decent results of mid 60s to low 70s with 20 epochs, past that overfitting destroys everythng\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sean\n",
    "\"\"\"\"\n",
    "Changing optimizer to Nadam with default parameters seems to yield pretty good result 70-75%. dropout rate=0.5. Higher rate decreases accuracy.\n",
    "\n",
    "Increasing second layer units decreased accuracy drastically. 16 <10%\n",
    "\n",
    "Increasing epochs and batch size has seemingly no effect.\n",
    "\n",
    "Rate = 0.5 seems optimal.\n",
    "\"\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Confidence interval\n",
    "# import keras.backend as K\n",
    "# f = K.function([model.layers[0].input, K.learning_phase()],\n",
    "#                [model.layers[-1].output])\n",
    "\n",
    "# def predict_with_uncertainty(f, x, n_iter=10):\n",
    "#     result = []\n",
    "\n",
    "#     for i in range(n_iter):\n",
    "#         result.append(f([x, 1]))\n",
    "\n",
    "#     result = np.array(result)\n",
    "\n",
    "#     prediction = result.mean(axis=0)\n",
    "#     uncertainty = result.var(axis=0)\n",
    "#     return prediction, uncertainty\n",
    "\n",
    "# prediction, uncertainty = predict_with_uncertainty(f, x_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(SEQUENCE_LENGTH, activation='sigmoid'))\n",
    "    model.add((LSTM(4, return_sequences=True,\n",
    "                           input_shape=(TIME_LENGTH, 4),\n",
    "                           dropout=0.5)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='sigmoid')) #FC1\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='relu')) #FC2\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='tanh'))#Output Layer\n",
    "    optimizer = Nadam()\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_x, train_y, test_x, test_y):\n",
    "    model.fit(train_x, train_y, epochs=30, batch_size=10)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4031/4031 [==============================] - 4s 895us/step - loss: 1.0628 - accuracy: 0.5125\n",
      "Epoch 2/30\n",
      "4031/4031 [==============================] - 2s 542us/step - loss: 0.7019 - accuracy: 0.6197\n",
      "Epoch 3/30\n",
      "4031/4031 [==============================] - 2s 549us/step - loss: 0.6350 - accuracy: 0.6634\n",
      "Epoch 4/30\n",
      "4031/4031 [==============================] - 2s 540us/step - loss: 0.6163 - accuracy: 0.6653\n",
      "Epoch 5/30\n",
      "4031/4031 [==============================] - 2s 550us/step - loss: 0.6102 - accuracy: 0.6683\n",
      "Epoch 6/30\n",
      "4031/4031 [==============================] - 2s 549us/step - loss: 0.6050 - accuracy: 0.6765\n",
      "Epoch 7/30\n",
      "4031/4031 [==============================] - 2s 551us/step - loss: 0.6092 - accuracy: 0.6706\n",
      "Epoch 8/30\n",
      "4031/4031 [==============================] - 2s 546us/step - loss: 0.6008 - accuracy: 0.6820\n",
      "Epoch 9/30\n",
      "4031/4031 [==============================] - 2s 543us/step - loss: 0.5996 - accuracy: 0.6785\n",
      "Epoch 10/30\n",
      "4031/4031 [==============================] - 2s 546us/step - loss: 0.6040 - accuracy: 0.6782\n",
      "Epoch 11/30\n",
      "4031/4031 [==============================] - 2s 544us/step - loss: 0.5990 - accuracy: 0.6795\n",
      "Epoch 12/30\n",
      "4031/4031 [==============================] - 2s 570us/step - loss: 0.5959 - accuracy: 0.6906\n",
      "Epoch 13/30\n",
      "4031/4031 [==============================] - 2s 567us/step - loss: 0.5875 - accuracy: 0.6993\n",
      "Epoch 14/30\n",
      "4031/4031 [==============================] - 3s 664us/step - loss: 0.5869 - accuracy: 0.7028\n",
      "Epoch 15/30\n",
      "4031/4031 [==============================] - 3s 667us/step - loss: 0.5849 - accuracy: 0.7048\n",
      "Epoch 16/30\n",
      "4031/4031 [==============================] - 2s 556us/step - loss: 0.5674 - accuracy: 0.7152\n",
      "Epoch 17/30\n",
      "4031/4031 [==============================] - 2s 545us/step - loss: 0.5733 - accuracy: 0.7093\n",
      "Epoch 18/30\n",
      "4031/4031 [==============================] - 2s 558us/step - loss: 0.5663 - accuracy: 0.7179\n",
      "Epoch 19/30\n",
      "4031/4031 [==============================] - 2s 548us/step - loss: 0.5625 - accuracy: 0.7202\n",
      "Epoch 20/30\n",
      "4031/4031 [==============================] - 2s 542us/step - loss: 0.5744 - accuracy: 0.7184\n",
      "Epoch 21/30\n",
      "4031/4031 [==============================] - 2s 542us/step - loss: 0.5907 - accuracy: 0.7234\n",
      "Epoch 22/30\n",
      "4031/4031 [==============================] - 2s 572us/step - loss: 0.5622 - accuracy: 0.7199\n",
      "Epoch 23/30\n",
      "4031/4031 [==============================] - 2s 592us/step - loss: 0.5613 - accuracy: 0.7259\n",
      "Epoch 24/30\n",
      "4031/4031 [==============================] - 2s 569us/step - loss: 0.5574 - accuracy: 0.7266\n",
      "Epoch 25/30\n",
      "4031/4031 [==============================] - 2s 560us/step - loss: 0.5696 - accuracy: 0.7182\n",
      "Epoch 26/30\n",
      "4031/4031 [==============================] - 2s 562us/step - loss: 0.5531 - accuracy: 0.7293\n",
      "Epoch 27/30\n",
      "4031/4031 [==============================] - 2s 560us/step - loss: 0.5503 - accuracy: 0.7308\n",
      "Epoch 28/30\n",
      "4031/4031 [==============================] - 2s 561us/step - loss: 0.5534 - accuracy: 0.7276\n",
      "Epoch 29/30\n",
      "4031/4031 [==============================] - 2s 560us/step - loss: 0.5541 - accuracy: 0.7303\n",
      "Epoch 30/30\n",
      "4031/4031 [==============================] - 2s 579us/step - loss: 0.5505 - accuracy: 0.7313\n",
      "accuracy: 76.21%\n",
      "Epoch 1/30\n",
      "4031/4031 [==============================] - 4s 976us/step - loss: 1.1665 - accuracy: 0.5200\n",
      "Epoch 2/30\n",
      "4031/4031 [==============================] - 2s 565us/step - loss: 1.5646 - accuracy: 0.5016\n",
      "Epoch 3/30\n",
      "4031/4031 [==============================] - 2s 580us/step - loss: 4.0167 - accuracy: 0.2952\n",
      "Epoch 4/30\n",
      "4031/4031 [==============================] - 2s 569us/step - loss: 4.0500 - accuracy: 0.3106\n",
      "Epoch 5/30\n",
      "4031/4031 [==============================] - 2s 571us/step - loss: 1.9002 - accuracy: 0.5391\n",
      "Epoch 6/30\n",
      "4031/4031 [==============================] - 3s 631us/step - loss: 0.6166 - accuracy: 0.6696\n",
      "Epoch 7/30\n",
      "4031/4031 [==============================] - 3s 668us/step - loss: 0.6100 - accuracy: 0.6735\n",
      "Epoch 8/30\n",
      "4031/4031 [==============================] - 3s 661us/step - loss: 0.5996 - accuracy: 0.6839\n",
      "Epoch 9/30\n",
      "4031/4031 [==============================] - 3s 666us/step - loss: 0.6052 - accuracy: 0.6723\n",
      "Epoch 10/30\n",
      "4031/4031 [==============================] - 2s 605us/step - loss: 0.6054 - accuracy: 0.6723\n",
      "Epoch 11/30\n",
      "4031/4031 [==============================] - 2s 571us/step - loss: 0.6083 - accuracy: 0.6730\n",
      "Epoch 12/30\n",
      "4031/4031 [==============================] - 2s 585us/step - loss: 0.6010 - accuracy: 0.6844\n",
      "Epoch 13/30\n",
      "4031/4031 [==============================] - 2s 590us/step - loss: 0.5929 - accuracy: 0.6906\n",
      "Epoch 14/30\n",
      "4031/4031 [==============================] - 2s 556us/step - loss: 0.5923 - accuracy: 0.6914\n",
      "Epoch 15/30\n",
      "4031/4031 [==============================] - 2s 556us/step - loss: 0.5912 - accuracy: 0.6874\n",
      "Epoch 16/30\n",
      "4031/4031 [==============================] - 2s 556us/step - loss: 0.5916 - accuracy: 0.6837\n",
      "Epoch 17/30\n",
      "4031/4031 [==============================] - 2s 561us/step - loss: 0.5878 - accuracy: 0.6902\n",
      "Epoch 18/30\n",
      "4031/4031 [==============================] - 2s 566us/step - loss: 0.5972 - accuracy: 0.6830\n",
      "Epoch 19/30\n",
      "4031/4031 [==============================] - 2s 578us/step - loss: 0.5960 - accuracy: 0.6894\n",
      "Epoch 20/30\n",
      "4031/4031 [==============================] - 2s 579us/step - loss: 0.5867 - accuracy: 0.6951\n",
      "Epoch 21/30\n",
      "4031/4031 [==============================] - 2s 599us/step - loss: 0.5867 - accuracy: 0.6991\n",
      "Epoch 22/30\n",
      "4031/4031 [==============================] - 2s 563us/step - loss: 0.5826 - accuracy: 0.6926\n",
      "Epoch 23/30\n",
      "4031/4031 [==============================] - 2s 551us/step - loss: 0.5788 - accuracy: 0.6966\n",
      "Epoch 24/30\n",
      "4031/4031 [==============================] - 2s 557us/step - loss: 0.5834 - accuracy: 0.6973\n",
      "Epoch 25/30\n",
      "4031/4031 [==============================] - 2s 558us/step - loss: 0.5825 - accuracy: 0.6968\n",
      "Epoch 26/30\n",
      "4031/4031 [==============================] - 2s 577us/step - loss: 0.5838 - accuracy: 0.7008\n",
      "Epoch 27/30\n",
      "4031/4031 [==============================] - 2s 557us/step - loss: 0.5770 - accuracy: 0.7006\n",
      "Epoch 28/30\n",
      "4031/4031 [==============================] - 2s 553us/step - loss: 0.5711 - accuracy: 0.7050\n",
      "Epoch 29/30\n",
      "4031/4031 [==============================] - 2s 553us/step - loss: 0.5785 - accuracy: 0.7045\n",
      "Epoch 30/30\n",
      "4031/4031 [==============================] - 2s 552us/step - loss: 0.5802 - accuracy: 0.7018\n",
      "accuracy: 72.84%\n",
      "Epoch 1/30\n",
      "4032/4032 [==============================] - 4s 941us/step - loss: 2.0736 - accuracy: 0.4707\n",
      "Epoch 2/30\n",
      "4032/4032 [==============================] - 2s 568us/step - loss: 0.7001 - accuracy: 0.6133\n",
      "Epoch 3/30\n",
      "4032/4032 [==============================] - 2s 590us/step - loss: 0.6458 - accuracy: 0.6386\n",
      "Epoch 4/30\n",
      "4032/4032 [==============================] - 2s 559us/step - loss: 0.6211 - accuracy: 0.6533\n",
      "Epoch 5/30\n",
      "4032/4032 [==============================] - 2s 561us/step - loss: 0.6252 - accuracy: 0.6438\n",
      "Epoch 6/30\n",
      "4032/4032 [==============================] - 2s 586us/step - loss: 0.6206 - accuracy: 0.6543\n",
      "Epoch 7/30\n",
      "4032/4032 [==============================] - 2s 557us/step - loss: 0.6156 - accuracy: 0.6620\n",
      "Epoch 8/30\n",
      "4032/4032 [==============================] - 2s 561us/step - loss: 0.6056 - accuracy: 0.6714\n",
      "Epoch 9/30\n",
      "4032/4032 [==============================] - 2s 561us/step - loss: 0.6062 - accuracy: 0.6773\n",
      "Epoch 10/30\n",
      "4032/4032 [==============================] - 2s 563us/step - loss: 0.6072 - accuracy: 0.6706\n",
      "Epoch 11/30\n",
      "4032/4032 [==============================] - 2s 573us/step - loss: 0.6090 - accuracy: 0.6739\n",
      "Epoch 12/30\n",
      "4032/4032 [==============================] - 2s 570us/step - loss: 0.5984 - accuracy: 0.6781\n",
      "Epoch 13/30\n",
      "4032/4032 [==============================] - 2s 576us/step - loss: 0.6005 - accuracy: 0.6813\n",
      "Epoch 14/30\n",
      "4032/4032 [==============================] - 2s 560us/step - loss: 0.6003 - accuracy: 0.6753\n",
      "Epoch 15/30\n",
      "4032/4032 [==============================] - 2s 564us/step - loss: 0.5976 - accuracy: 0.6791\n",
      "Epoch 16/30\n",
      "4032/4032 [==============================] - 2s 572us/step - loss: 0.5963 - accuracy: 0.6828\n",
      "Epoch 17/30\n",
      "4032/4032 [==============================] - 2s 553us/step - loss: 0.5949 - accuracy: 0.6858\n",
      "Epoch 18/30\n",
      "4032/4032 [==============================] - 2s 543us/step - loss: 0.5987 - accuracy: 0.6835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "4032/4032 [==============================] - 2s 545us/step - loss: 0.5972 - accuracy: 0.6882\n",
      "Epoch 20/30\n",
      "4032/4032 [==============================] - 2s 552us/step - loss: 0.6004 - accuracy: 0.6776\n",
      "Epoch 21/30\n",
      "4032/4032 [==============================] - 2s 546us/step - loss: 0.5918 - accuracy: 0.6902\n",
      "Epoch 22/30\n",
      "4032/4032 [==============================] - 2s 540us/step - loss: 0.5914 - accuracy: 0.6900\n",
      "Epoch 23/30\n",
      "4032/4032 [==============================] - 2s 547us/step - loss: 0.5843 - accuracy: 0.6964\n",
      "Epoch 24/30\n",
      "4032/4032 [==============================] - 2s 546us/step - loss: 0.5841 - accuracy: 0.6910\n",
      "Epoch 25/30\n",
      "4032/4032 [==============================] - 2s 539us/step - loss: 0.5839 - accuracy: 0.6922\n",
      "Epoch 26/30\n",
      "4032/4032 [==============================] - 2s 552us/step - loss: 0.5874 - accuracy: 0.6947\n",
      "Epoch 27/30\n",
      "4032/4032 [==============================] - 2s 549us/step - loss: 0.5829 - accuracy: 0.6947\n",
      "Epoch 28/30\n",
      "4032/4032 [==============================] - 2s 558us/step - loss: 0.5875 - accuracy: 0.6885\n",
      "Epoch 29/30\n",
      "4032/4032 [==============================] - 2s 564us/step - loss: 0.5951 - accuracy: 0.6877\n",
      "Epoch 30/30\n",
      "4032/4032 [==============================] - 2s 564us/step - loss: 0.5862 - accuracy: 0.6855\n",
      "accuracy: 73.02%\n",
      "Epoch 1/30\n",
      "4033/4033 [==============================] - 4s 954us/step - loss: 1.6507 - accuracy: 0.4850\n",
      "Epoch 2/30\n",
      "4033/4033 [==============================] - 2s 567us/step - loss: 0.7309 - accuracy: 0.5946\n",
      "Epoch 3/30\n",
      "4033/4033 [==============================] - 2s 562us/step - loss: 0.6508 - accuracy: 0.6588\n",
      "Epoch 4/30\n",
      "4033/4033 [==============================] - 2s 557us/step - loss: 0.6140 - accuracy: 0.6782\n",
      "Epoch 5/30\n",
      "4033/4033 [==============================] - 2s 545us/step - loss: 0.6054 - accuracy: 0.6772\n",
      "Epoch 6/30\n",
      "4033/4033 [==============================] - 2s 555us/step - loss: 0.5922 - accuracy: 0.6839\n",
      "Epoch 7/30\n",
      "4033/4033 [==============================] - 2s 557us/step - loss: 0.5957 - accuracy: 0.6787\n",
      "Epoch 8/30\n",
      "4033/4033 [==============================] - 2s 549us/step - loss: 0.5862 - accuracy: 0.6868\n",
      "Epoch 9/30\n",
      "4033/4033 [==============================] - 3s 658us/step - loss: 0.5837 - accuracy: 0.6972\n",
      "Epoch 10/30\n",
      "4033/4033 [==============================] - 2s 550us/step - loss: 0.5822 - accuracy: 0.6995\n",
      "Epoch 11/30\n",
      "4033/4033 [==============================] - 2s 556us/step - loss: 0.5815 - accuracy: 0.7022\n",
      "Epoch 12/30\n",
      "4033/4033 [==============================] - 2s 553us/step - loss: 0.5806 - accuracy: 0.7002\n",
      "Epoch 13/30\n",
      "4033/4033 [==============================] - 2s 557us/step - loss: 0.5764 - accuracy: 0.7044\n",
      "Epoch 14/30\n",
      "4033/4033 [==============================] - 2s 555us/step - loss: 0.5772 - accuracy: 0.7012\n",
      "Epoch 15/30\n",
      "4033/4033 [==============================] - 2s 549us/step - loss: 0.5787 - accuracy: 0.7034\n",
      "Epoch 16/30\n",
      "4033/4033 [==============================] - 2s 567us/step - loss: 0.5776 - accuracy: 0.7049\n",
      "Epoch 17/30\n",
      "4033/4033 [==============================] - 2s 551us/step - loss: 0.5740 - accuracy: 0.7037\n",
      "Epoch 18/30\n",
      "4033/4033 [==============================] - 2s 551us/step - loss: 0.5666 - accuracy: 0.7101\n",
      "Epoch 19/30\n",
      "4033/4033 [==============================] - 2s 556us/step - loss: 0.5668 - accuracy: 0.7178\n",
      "Epoch 20/30\n",
      "4033/4033 [==============================] - 2s 557us/step - loss: 0.5828 - accuracy: 0.7012\n",
      "Epoch 21/30\n",
      "4033/4033 [==============================] - 2s 550us/step - loss: 0.5738 - accuracy: 0.7119\n",
      "Epoch 22/30\n",
      "4033/4033 [==============================] - 2s 547us/step - loss: 0.5664 - accuracy: 0.7101\n",
      "Epoch 23/30\n",
      "4033/4033 [==============================] - 2s 556us/step - loss: 0.5739 - accuracy: 0.7149\n",
      "Epoch 24/30\n",
      "4033/4033 [==============================] - 2s 551us/step - loss: 0.5655 - accuracy: 0.7096\n",
      "Epoch 25/30\n",
      "4033/4033 [==============================] - 2s 551us/step - loss: 0.5630 - accuracy: 0.7114\n",
      "Epoch 26/30\n",
      "4033/4033 [==============================] - 2s 552us/step - loss: 0.5636 - accuracy: 0.7163\n",
      "Epoch 27/30\n",
      "4033/4033 [==============================] - 2s 552us/step - loss: 0.5717 - accuracy: 0.7039\n",
      "Epoch 28/30\n",
      "4033/4033 [==============================] - 2s 554us/step - loss: 0.5646 - accuracy: 0.7121\n",
      "Epoch 29/30\n",
      "4033/4033 [==============================] - 2s 595us/step - loss: 0.5631 - accuracy: 0.7124\n",
      "Epoch 30/30\n",
      "4033/4033 [==============================] - 2s 607us/step - loss: 0.5710 - accuracy: 0.7109\n",
      "accuracy: 70.90%\n",
      "Epoch 1/30\n",
      "4033/4033 [==============================] - 4s 949us/step - loss: 5.4202 - accuracy: 0.2155\n",
      "Epoch 2/30\n",
      "4033/4033 [==============================] - 2s 544us/step - loss: 4.2829 - accuracy: 0.2566\n",
      "Epoch 3/30\n",
      "4033/4033 [==============================] - 2s 603us/step - loss: 4.2321 - accuracy: 0.2789\n",
      "Epoch 4/30\n",
      "4033/4033 [==============================] - 3s 673us/step - loss: 4.2142 - accuracy: 0.3015\n",
      "Epoch 5/30\n",
      "4033/4033 [==============================] - 2s 617us/step - loss: 4.1355 - accuracy: 0.2953\n",
      "Epoch 6/30\n",
      "4033/4033 [==============================] - 2s 542us/step - loss: 4.2309 - accuracy: 0.3030\n",
      "Epoch 7/30\n",
      "4033/4033 [==============================] - 2s 535us/step - loss: 4.0491 - accuracy: 0.3082\n",
      "Epoch 8/30\n",
      "4033/4033 [==============================] - 2s 543us/step - loss: 4.2040 - accuracy: 0.3102\n",
      "Epoch 9/30\n",
      "4033/4033 [==============================] - 2s 558us/step - loss: 4.1260 - accuracy: 0.3020\n",
      "Epoch 10/30\n",
      "4033/4033 [==============================] - 2s 559us/step - loss: 4.1218 - accuracy: 0.2958\n",
      "Epoch 11/30\n",
      "4033/4033 [==============================] - 2s 539us/step - loss: 4.0256 - accuracy: 0.3057\n",
      "Epoch 12/30\n",
      "4033/4033 [==============================] - 2s 537us/step - loss: 0.8531 - accuracy: 0.5909\n",
      "Epoch 13/30\n",
      "4033/4033 [==============================] - 2s 542us/step - loss: 0.6546 - accuracy: 0.6107\n",
      "Epoch 14/30\n",
      "4033/4033 [==============================] - 2s 545us/step - loss: 0.6493 - accuracy: 0.6075\n",
      "Epoch 15/30\n",
      "4033/4033 [==============================] - 2s 539us/step - loss: 0.6440 - accuracy: 0.6102\n",
      "Epoch 16/30\n",
      "4033/4033 [==============================] - 2s 557us/step - loss: 0.6427 - accuracy: 0.6095\n",
      "Epoch 17/30\n",
      "4033/4033 [==============================] - 2s 557us/step - loss: 0.6475 - accuracy: 0.6020\n",
      "Epoch 18/30\n",
      "4033/4033 [==============================] - 2s 544us/step - loss: 0.6408 - accuracy: 0.6092\n",
      "Epoch 19/30\n",
      "4033/4033 [==============================] - 2s 549us/step - loss: 0.6472 - accuracy: 0.6043\n",
      "Epoch 20/30\n",
      "4033/4033 [==============================] - 2s 552us/step - loss: 0.6400 - accuracy: 0.6149\n",
      "Epoch 21/30\n",
      "4033/4033 [==============================] - 2s 543us/step - loss: 0.6364 - accuracy: 0.6154\n",
      "Epoch 22/30\n",
      "4033/4033 [==============================] - 2s 550us/step - loss: 0.6387 - accuracy: 0.6139\n",
      "Epoch 23/30\n",
      "4033/4033 [==============================] - 2s 554us/step - loss: 0.6465 - accuracy: 0.6043\n",
      "Epoch 24/30\n",
      "4033/4033 [==============================] - 2s 558us/step - loss: 0.6409 - accuracy: 0.6090\n",
      "Epoch 25/30\n",
      "4033/4033 [==============================] - 2s 547us/step - loss: 0.6436 - accuracy: 0.6013\n",
      "Epoch 26/30\n",
      "4033/4033 [==============================] - 2s 546us/step - loss: 0.6443 - accuracy: 0.6105\n",
      "Epoch 27/30\n",
      "4033/4033 [==============================] - 2s 547us/step - loss: 0.6398 - accuracy: 0.6127\n",
      "Epoch 28/30\n",
      "4033/4033 [==============================] - 2s 549us/step - loss: 0.6382 - accuracy: 0.6142\n",
      "Epoch 29/30\n",
      "4033/4033 [==============================] - 2s 550us/step - loss: 0.6395 - accuracy: 0.6152\n",
      "Epoch 30/30\n",
      "4033/4033 [==============================] - 2s 563us/step - loss: 0.6360 - accuracy: 0.6189\n",
      "accuracy: 72.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "labels = np.concatenate([data_y, y_validation_data])\n",
    "data = np.concatenate([data_x, x_validation_data])\n",
    "# labels = data_y.concat(data_x)\n",
    "scores = []\n",
    "n_folds = 5\n",
    "    \n",
    "skf = StratifiedKFold(labels, n_folds=n_folds, shuffle=True)\n",
    "for i, (train, test) in enumerate(skf):\n",
    "        eval_model = None # Clearing the NN.\n",
    "        eval_model = new_model()\n",
    "        score = train_and_evaluate(eval_model, data[train], labels[train], data[test], labels[test])\n",
    "        scores.append(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROC score\n",
    "pred = model.predict(x_validation_data).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7322721354166666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_validation_data, pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00104167, 0.17291667, 0.17291667, 0.17395833, 0.17395833,\n",
       "       0.190625  , 0.190625  , 0.20208333, 0.20208333, 0.22916667,\n",
       "       0.22916667, 0.23645833, 0.23645833, 0.24166667, 0.24166667,\n",
       "       0.24270833, 0.24270833, 0.25208333, 0.25208333, 0.25520833,\n",
       "       0.25520833, 0.25729167, 0.25729167, 0.26041667, 0.26041667,\n",
       "       0.26458333, 0.26458333, 0.26875   , 0.26875   , 0.27708333,\n",
       "       0.27708333, 0.28020833, 0.28020833, 0.2875    , 0.2875    ,\n",
       "       0.30208333, 0.30208333, 0.30416667, 0.30416667, 0.30520833,\n",
       "       0.30520833, 0.30729167, 0.30729167, 0.30833333, 0.30833333,\n",
       "       0.309375  , 0.309375  , 0.31666667, 0.31666667, 0.32291667,\n",
       "       0.32291667, 0.32395833, 0.32395833, 0.32604167, 0.32604167,\n",
       "       0.33125   , 0.33125   , 0.33541667, 0.33541667, 0.3375    ,\n",
       "       0.3375    , 0.340625  , 0.340625  , 0.34583333, 0.34583333,\n",
       "       0.346875  , 0.346875  , 0.34895833, 0.34895833, 0.353125  ,\n",
       "       0.353125  , 0.35520833, 0.35520833, 0.36041667, 0.36041667,\n",
       "       0.36458333, 0.36458333, 0.36666667, 0.36666667, 0.378125  ,\n",
       "       0.378125  , 0.38333333, 0.38333333, 0.38541667, 0.38541667,\n",
       "       0.39583333, 0.39583333, 0.39895833, 0.39895833, 0.40104167,\n",
       "       0.40104167, 0.40208333, 0.40208333, 0.40833333, 0.40833333,\n",
       "       0.409375  , 0.409375  , 0.41041667, 0.41041667, 0.41354167,\n",
       "       0.41354167, 0.421875  , 0.421875  , 0.42708333, 0.42708333,\n",
       "       0.43020833, 0.43020833, 0.43958333, 0.43958333, 0.440625  ,\n",
       "       0.440625  , 0.44375   , 0.44375   , 0.44791667, 0.44791667,\n",
       "       0.44895833, 0.44895833, 0.453125  , 0.453125  , 0.45520833,\n",
       "       0.45520833, 0.45729167, 0.45729167, 0.45833333, 0.45833333,\n",
       "       0.459375  , 0.459375  , 0.4625    , 0.4625    , 0.46354167,\n",
       "       0.46354167, 0.465625  , 0.465625  , 0.46666667, 0.46666667,\n",
       "       0.46979167, 0.46979167, 0.471875  , 0.471875  , 0.47291667,\n",
       "       0.47291667, 0.475     , 0.475     , 0.48020833, 0.48020833,\n",
       "       0.48125   , 0.48125   , 0.48229167, 0.48229167, 0.48333333,\n",
       "       0.48333333, 0.48541667, 0.48541667, 0.4875    , 0.4875    ,\n",
       "       0.48854167, 0.48854167, 0.49375   , 0.49375   , 0.49791667,\n",
       "       0.49791667, 0.49895833, 0.49895833, 0.5       , 0.5       ,\n",
       "       0.50104167, 0.50104167, 0.50729167, 0.50729167, 0.50833333,\n",
       "       0.50833333, 0.51041667, 0.51041667, 0.5125    , 0.5125    ,\n",
       "       0.51354167, 0.51354167, 0.51875   , 0.51875   , 0.51979167,\n",
       "       0.51979167, 0.521875  , 0.521875  , 0.52291667, 0.52291667,\n",
       "       0.525     , 0.525     , 0.52604167, 0.52604167, 0.534375  ,\n",
       "       0.534375  , 0.53541667, 0.53541667, 0.5375    , 0.5375    ,\n",
       "       0.53958333, 0.53958333, 0.54166667, 0.54166667, 0.54270833,\n",
       "       0.54270833, 0.54375   , 0.54375   , 0.546875  , 0.546875  ,\n",
       "       0.54791667, 0.54791667, 0.54895833, 0.54895833, 0.55      ,\n",
       "       0.55      , 0.55104167, 0.55104167, 0.55208333, 0.55208333,\n",
       "       0.55416667, 0.55416667, 0.55520833, 0.55520833, 0.55833333,\n",
       "       0.55833333, 0.559375  , 0.559375  , 0.5625    , 0.5625    ,\n",
       "       0.56354167, 0.56354167, 0.56458333, 0.56458333, 0.56666667,\n",
       "       0.56666667, 0.56979167, 0.56979167, 0.57291667, 0.57291667,\n",
       "       0.57395833, 0.57395833, 0.57604167, 0.57604167, 0.58020833,\n",
       "       0.58020833, 0.58229167, 0.58229167, 0.584375  , 0.584375  ,\n",
       "       0.58541667, 0.58541667, 0.58645833, 0.58645833, 0.5875    ,\n",
       "       0.5875    , 0.58958333, 0.58958333, 0.590625  , 0.590625  ,\n",
       "       0.59166667, 0.59166667, 0.59583333, 0.59583333, 0.596875  ,\n",
       "       0.596875  , 0.59791667, 0.59791667, 0.59895833, 0.59895833,\n",
       "       0.6       , 0.6       , 0.60208333, 0.60208333, 0.603125  ,\n",
       "       0.603125  , 0.60416667, 0.60416667, 0.60520833, 0.60520833,\n",
       "       0.60625   , 0.60625   , 0.60833333, 0.60833333, 0.61041667,\n",
       "       0.61041667, 0.6125    , 0.6125    , 0.61458333, 0.61458333,\n",
       "       0.615625  , 0.615625  , 0.61666667, 0.61666667, 0.61770833,\n",
       "       0.61770833, 0.62395833, 0.62395833, 0.62708333, 0.62708333,\n",
       "       0.628125  , 0.628125  , 0.63020833, 0.63020833, 0.634375  ,\n",
       "       0.634375  , 0.640625  , 0.640625  , 0.64270833, 0.64270833,\n",
       "       0.64375   , 0.64375   , 0.64479167, 0.64479167, 0.64791667,\n",
       "       0.64791667, 0.64895833, 0.64895833, 0.65104167, 0.65104167,\n",
       "       0.65208333, 0.65208333, 0.653125  , 0.653125  , 0.65625   ,\n",
       "       0.65625   , 1.        ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
